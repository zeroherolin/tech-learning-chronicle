# AI编译器基础

## Compiler

- 常规编译器组成部分划分：前端（frontend）、优化器（optimizer）、后端（backend）

- IR的目的：保证编译器跨硬件平台

- 高阶IR：侧重抽象计算和控制流，捕获AI模型特性

- 低阶IR：注重硬件相关细节和代码生成，细粒度反映硬件相关优化和布局

- AI编译器：输入模型，硬件无关的前端优化，硬件相关的后端优化和代码生成

- 高阶IR（图IR）通常形式：有向无环图，节点代表计算操作 ，边代表数据依赖关系

## LLVM

- LLVM IR与语言、指令集、类型系统无关，指令是SSA（Static Single Assignment，静态单赋值）形式

- LLVM由Clang前端、IR优化器和LLVM后端组成

- LLVM前端：词法分析器分解为Token，语法分析器识别程序语法结构，语义分析器组装表达式和语句函数等，输出AST

- LLVM后端：与目标平台无关的IR指令转换为目标平台相关的机器指令

## GPGPU

- CUDA C/C++程序的标准编译过程是将运行在GPGPU设备上的函数编译为PTX代码

- Clang的CUDA前端在生成AST后，以两种模式分别预处理和解析输入的混合模式源文件 \
一种模式为主机生成LLVM IR，另一种模式为设备生成LLVM IR

- GPU编译优化方法建立在对GPU体系结构、存储结构基础上

## 开源AI编译器

### TVM

- 前端：Relay层负责将不同深度学习框架转换为统一表示，并在计算图层面进行优化

- 后端：TVM层负责具体算子的优化，采用计算和调度分离的设计

- 张量表达式语言：第一部分指定输出张量形状，第二部分描述张量中每个元素的计算规则

- 调度：指定如何执行计算，如访问数据的顺序、多线程并行的方式

- 张量化是指将低阶数据转换或映射为高阶数据的过程

- TVM通过张量intrinsic声明机制将目标硬件intrinsic与调度分离

- 针对大型搜索空间，TVM的XGBTuner调优器通过并行模拟退火算法寻找问题的最优解

### XLA

- XLA两级IR：HLO IR和低阶IR

- XLA是优化HLO并将其降级为机器码的后端框架

- XLA编译器通过编译子图并可缓存复用，减少短时操作的执行时间

***
🔙 [Go Back](README.md)
