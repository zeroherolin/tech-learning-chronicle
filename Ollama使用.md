# Ollamaä½¿ç”¨

Webpage: [https://ollama.com/download](https://ollama.com/download)

## å®‰è£…

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

> Installing ollama to /usr/local \
Downloading Linux amd64 bundle \
######################################################################## 100.0%##O=#  # \
Creating ollama user... \
Adding ollama user to render group... \
Adding ollama user to video group... \
Adding current user to ollama group... \
Creating ollama systemd service... \
Enabling and starting ollama service... \
Created symlink /etc/systemd/system/default.target.wants/ollama.service â†’ /etc/systemd/system/ollama.service. \
NVIDIA GPU installed.

## é…ç½®

- ç¼–è¾‘ollama.service

```bash
sudo nano /etc/systemd/system/ollama.service
```

æ·»åŠ å¦‚ä¸‹å†…å®¹ï¼š

```
[Unit]
Description=Ollama Service
After=network-online.target

[Service]
ExecStart=/usr/local/bin/ollama serve
User=ollama
Group=ollama
Restart=always
RestartSec=3
Environment="OLLAMA_HOST=0.0.0.0:11434"

[Install]
WantedBy=default.target
```

- é‡å¯æœåŠ¡

```bash
systemctl daemon-reload
systemctl restart ollama
```

## è®¿é—®æµ‹è¯•

[http://192.168.3.88:11434/](http://192.168.3.88:11434/)

> Ollama is running

## Ollamaå‘½ä»¤

```bash
ollama serve     # å¯åŠ¨ollama
ollama create    # ä»æ¨¡å‹æ–‡ä»¶åˆ›å»ºæ¨¡å‹
ollama show      # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
ollama run       # è¿è¡Œæ¨¡å‹
ollama pull      # ä»æ³¨å†Œä»“åº“ä¸­æ‹‰å–æ¨¡å‹
ollama push      # å°†æ¨¡å‹æ¨é€åˆ°æ³¨å†Œä»“åº“
ollama list      # åˆ—å‡ºå·²ä¸‹è½½æ¨¡å‹
ollama cp        # å¤åˆ¶æ¨¡å‹
ollama rm        # åˆ é™¤æ¨¡å‹
ollama help      # è·å–æœ‰å…³ä»»ä½•å‘½ä»¤çš„å¸®åŠ©ä¿¡æ¯
```

## ç¤ºä¾‹

æ¨¡å‹åº“æŸ¥çœ‹ï¼š[https://ollama.com/library](https://ollama.com/library)

- Run

```bash
ollama pull llama3:8b
ollama list
ollama run llama3:8b
```

- Chat via API

```bash
curl http://192.168.3.88:11434/api/chat -d '{"model": "llama3:8b", "messages": [{ "role": "user", "content": "ä½ å¥½å•Š"}]}'

curl http://192.168.3.88:11434/api/chat -d '{"model": "llama3:8b", "messages": [{"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„AIåŠ©æ‰‹ã€‚"}, {"role": "user", "content": "ä½ å¥½å•Š"}], "stream": false}'

curl http://192.168.3.88:11434/api/chat -d '{"model": "wangshenzhi/llama3-8b-chinese-chat-ollama-q4:latest", "messages": [{"role": "system", "content": "ä½ æ˜¯å¥¥ç‰¹æ›¼ã€‚"}, {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"}], "stream": false}'
```

## åœæ­¢

```bash
sudo systemctl stop ollama.service
```

## å¸è½½

```bash
sudo systemctl stop ollama
sudo systemctl disable ollama
sudo rm /etc/systemd/system/ollama.service

sudo rm $(which ollama)

sudo rm -r /usr/share/ollama
sudo userdel ollama
sudo groupdel ollama
```

***
ğŸ”™ [Go Back](README.md)
